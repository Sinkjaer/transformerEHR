{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!ls -a"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".\t\t   .gitignore\t\t   behrtmlmazure.ipynb.amltmp\r\n..\t\t   .ipynb_aml_checkpoints  common\r\n.DS_Store\t   .vscode\t\t   data\r\n.amlignore\t   __pycache__\t\t   dataLoader\r\n.amlignore.amltmp  behrt.yml\t\t   model\r\n.git\t\t   behrtMLMAzure.ipynb\t   task\r\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move files to datastore and make smaller folder that has only the necessary files\n",
        "\n",
        "from azureml.core import Workspace, Experiment, Environment\n",
        "from azureml.core.script_run_config import ScriptRunConfig\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "import azureml._restclient.snapshots_client\n",
        "\n",
        "# Set the desired snapshot size (in bytes)\n",
        "snapshot_size = 1073741824\n",
        "\n",
        "# Update the maximum snapshot size\n",
        "azureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = snapshot_size\n",
        "\n",
        "\n",
        "# Retrieve Workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Get the Curated Environment\n",
        "# env = Environment.get(workspace=ws, name=\"AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\")\n",
        "env = Environment.get(workspace=ws, name=\"AzureML-ACPT-pytorch-1.11-py38-cuda11.3-gpu\")\n",
        "\n",
        "\n",
        "\n",
        "# # Define additional conda and pip packages you want to install\n",
        "conda_dep = CondaDependencies()\n",
        "\n",
        "conda_dep.add_pip_package(\"lightning\")  \n",
        "\n",
        "env.python.conda_dependencies=conda_dep\n",
        "\n",
        "# Define the Training Script and Directory\n",
        "script_folder = ''\n",
        "script_name = 'task/executeBehrtMLM.py'  # your training script\n",
        "\n",
        "# Create an Experiment\n",
        "experiment_name = 'My-Experiment'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "\n",
        "# Configure and Submit the Training Job\n",
        "src = ScriptRunConfig(source_directory=script_folder,\n",
        "                      script=script_name,\n",
        "                      environment=env)  # specifying the cloned environment here\n",
        "\n",
        "run = experiment.submit(src)\n",
        "run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ExperimentExecutionException",
          "evalue": "ExperimentExecutionException:\n\tMessage: {\n    \"error_details\": {\n        \"componentName\": \"execution\",\n        \"correlation\": {\n            \"operation\": \"b8e5051c8d1be3341ef29989e66b550d\",\n            \"request\": \"4a49f74d45b3d465\"\n        },\n        \"environment\": \"westeurope\",\n        \"error\": {\n            \"code\": \"UserError\",\n            \"message\": \"Environment name cannot start with the prefix AzureML. To alter a curated environment first create a copy of it.\"\n        },\n        \"location\": \"westeurope\",\n        \"time\": \"2023-08-12T09:29:10.3240875+00:00\"\n    },\n    \"status_code\": 400,\n    \"url\": \"https://cd7411a6-1444-4dc7-ad9f-0eed2fcbd115.workspace.westeurope.api.azureml.ms/execution/v1.0/subscriptions/f8c5aac3-29fc-4387-858a-1f61722fb57a/resourceGroups/forskerpl-p2ss0q-rg/providers/Microsoft.MachineLearningServices/workspaces/forskerpl-p2ss0q-mlw/experiments/My-Experiment/localrun?runId=My-Experiment_1691832492_f5a70200\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"{\\n    \\\"error_details\\\": {\\n        \\\"componentName\\\": \\\"execution\\\",\\n        \\\"correlation\\\": {\\n            \\\"operation\\\": \\\"b8e5051c8d1be3341ef29989e66b550d\\\",\\n            \\\"request\\\": \\\"4a49f74d45b3d465\\\"\\n        },\\n        \\\"environment\\\": \\\"westeurope\\\",\\n        \\\"error\\\": {\\n            \\\"code\\\": \\\"UserError\\\",\\n            \\\"message\\\": \\\"Environment name cannot start with the prefix AzureML. To alter a curated environment first create a copy of it.\\\"\\n        },\\n        \\\"location\\\": \\\"westeurope\\\",\\n        \\\"time\\\": \\\"2023-08-12T09:29:10.3240875+00:00\\\"\\n    },\\n    \\\"status_code\\\": 400,\\n    \\\"url\\\": \\\"https://cd7411a6-1444-4dc7-ad9f-0eed2fcbd115.workspace.westeurope.api.azureml.ms/execution/v1.0/subscriptions/f8c5aac3-29fc-4387-858a-1f61722fb57a/resourceGroups/forskerpl-p2ss0q-rg/providers/Microsoft.MachineLearningServices/workspaces/forskerpl-p2ss0q-mlw/experiments/My-Experiment/localrun?runId=My-Experiment_1691832492_f5a70200\\\"\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mExperimentExecutionException\u001b[0m              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 43\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Configure and Submit the Training Job\u001b[39;00m\n\u001b[1;32m     39\u001b[0m src \u001b[38;5;241m=\u001b[39m ScriptRunConfig(source_directory\u001b[38;5;241m=\u001b[39mscript_folder,\n\u001b[1;32m     40\u001b[0m                       script\u001b[38;5;241m=\u001b[39mscript_name,\n\u001b[1;32m     41\u001b[0m                       environment\u001b[38;5;241m=\u001b[39menv)  \u001b[38;5;66;03m# specifying the cloned environment here\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m run\u001b[38;5;241m.\u001b[39mwait_for_completion(show_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azureml/core/experiment.py:238\u001b[0m, in \u001b[0;36mExperiment.submit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m submit_func \u001b[38;5;241m=\u001b[39m get_experiment_submit(config)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmit config \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)):\n\u001b[0;32m--> 238\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43msubmit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     run\u001b[38;5;241m.\u001b[39mset_tags(tags)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azureml/core/script_run_config.py:63\u001b[0m, in \u001b[0;36msubmit\u001b[0;34m(script_run_config, workspace, experiment_name, run_id, _parent_run_id, credential_passthrough)\u001b[0m\n\u001b[1;32m     60\u001b[0m inputs, _ \u001b[38;5;241m=\u001b[39m _update_args_and_io(workspace, run_config)\n\u001b[1;32m     61\u001b[0m collect_datasets_usage(module_logger, _SCRIPT_RUN_SUBMIT_ACTIVITY, inputs,\n\u001b[1;32m     62\u001b[0m                        workspace, run_config\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[0;32m---> 63\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43m_commands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtelemetry_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscript_run_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_telemetry_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_run_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_parent_run_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m run\u001b[38;5;241m.\u001b[39madd_properties(global_tracking_info_registry\u001b[38;5;241m.\u001b[39mgather_all(script_run_config\u001b[38;5;241m.\u001b[39msource_directory))\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azureml/_execution/_commands.py:117\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(project_object, run_config_object, run_id, injected_files, telemetry_values, parent_run_id, prepare_only, check)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prepare_only \u001b[38;5;129;01mand\u001b[39;00m check:\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExperimentExecutionException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not check preparation of local targets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_start_internal_local_cloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mshared_start_run_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _start_internal(project_object, run_config_object, prepare_check\u001b[38;5;241m=\u001b[39mcheck,\n\u001b[1;32m    121\u001b[0m                            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mshared_start_run_kwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azureml/_execution/_commands.py:268\u001b[0m, in \u001b[0;36m_start_internal_local_cloud\u001b[0;34m(project_object, run_config_object, prepare_only, custom_target_dict, run_id, injected_files, telemetry_values, parent_run_id)\u001b[0m\n\u001b[1;32m    265\u001b[0m uri \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m run_id_query\n\u001b[1;32m    267\u001b[0m response \u001b[38;5;241m=\u001b[39m ClientBase\u001b[38;5;241m.\u001b[39m_execute_func(requests\u001b[38;5;241m.\u001b[39mpost, uri, files\u001b[38;5;241m=\u001b[39mfiles, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m--> 268\u001b[0m \u001b[43m_raise_request_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstarting run\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m invocation_zip_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(project_temp_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvocation.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(invocation_zip_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azureml/_execution/_commands.py:570\u001b[0m, in \u001b[0;36m_raise_request_error\u001b[0;34m(response, action)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# response.text is a JSON from execution service.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m response_message \u001b[38;5;241m=\u001b[39m get_http_exception_response_string(response)\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ExperimentExecutionException(response_message)\n",
            "\u001b[0;31mExperimentExecutionException\u001b[0m: ExperimentExecutionException:\n\tMessage: {\n    \"error_details\": {\n        \"componentName\": \"execution\",\n        \"correlation\": {\n            \"operation\": \"b8e5051c8d1be3341ef29989e66b550d\",\n            \"request\": \"4a49f74d45b3d465\"\n        },\n        \"environment\": \"westeurope\",\n        \"error\": {\n            \"code\": \"UserError\",\n            \"message\": \"Environment name cannot start with the prefix AzureML. To alter a curated environment first create a copy of it.\"\n        },\n        \"location\": \"westeurope\",\n        \"time\": \"2023-08-12T09:29:10.3240875+00:00\"\n    },\n    \"status_code\": 400,\n    \"url\": \"https://cd7411a6-1444-4dc7-ad9f-0eed2fcbd115.workspace.westeurope.api.azureml.ms/execution/v1.0/subscriptions/f8c5aac3-29fc-4387-858a-1f61722fb57a/resourceGroups/forskerpl-p2ss0q-rg/providers/Microsoft.MachineLearningServices/workspaces/forskerpl-p2ss0q-mlw/experiments/My-Experiment/localrun?runId=My-Experiment_1691832492_f5a70200\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"{\\n    \\\"error_details\\\": {\\n        \\\"componentName\\\": \\\"execution\\\",\\n        \\\"correlation\\\": {\\n            \\\"operation\\\": \\\"b8e5051c8d1be3341ef29989e66b550d\\\",\\n            \\\"request\\\": \\\"4a49f74d45b3d465\\\"\\n        },\\n        \\\"environment\\\": \\\"westeurope\\\",\\n        \\\"error\\\": {\\n            \\\"code\\\": \\\"UserError\\\",\\n            \\\"message\\\": \\\"Environment name cannot start with the prefix AzureML. To alter a curated environment first create a copy of it.\\\"\\n        },\\n        \\\"location\\\": \\\"westeurope\\\",\\n        \\\"time\\\": \\\"2023-08-12T09:29:10.3240875+00:00\\\"\\n    },\\n    \\\"status_code\\\": 400,\\n    \\\"url\\\": \\\"https://cd7411a6-1444-4dc7-ad9f-0eed2fcbd115.workspace.westeurope.api.azureml.ms/execution/v1.0/subscriptions/f8c5aac3-29fc-4387-858a-1f61722fb57a/resourceGroups/forskerpl-p2ss0q-rg/providers/Microsoft.MachineLearningServices/workspaces/forskerpl-p2ss0q-mlw/experiments/My-Experiment/localrun?runId=My-Experiment_1691832492_f5a70200\\\"\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691832550889
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env list\n",
        "!conda activate --stack azureml_py38_PT_TF\n",
        "\n",
        "# !pip install torchtext"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "# conda environments:\r\n#\r\nbase                     /anaconda\r\nazureml_py310_sdkv2      /anaconda/envs/azureml_py310_sdkv2\r\nazureml_py38             /anaconda/envs/azureml_py38\r\nazureml_py38_PT_TF       /anaconda/envs/azureml_py38_PT_TF\r\nbehrt_cpu                /anaconda/envs/behrt_cpu\r\njupyter_env              /anaconda/envs/jupyter_env\r\n\r\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691833353869
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "\n",
        "# sys.path.insert(0, \"../\")\n",
        "from common.common import create_folder\n",
        "from dataLoader.build_vocab import build_vocab\n",
        "import pytorch_pretrained_bert as Bert\n",
        "from dataLoader.dataLoaderMLM import MaskedDataset\n",
        "from model.behrt import BertModel, BertMLM\n",
        "from torch.utils.data import DataLoader\n",
        "import json\n",
        "import os\n",
        "import lightning.pytorch as pl\n",
        "from lightning.pytorch.loggers import NeptuneLogger\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from lightning.pytorch.tuner import Tuner\n",
        "\n",
        "Azure = True\n",
        "\n",
        "# Initialize Neptune\n",
        "name_experiment = \"MLM_model\"\n",
        "neptune_logger = NeptuneLogger(\n",
        "    project=\"sinkjaer/BEHRT\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzOWVmOWI3Mi1jNjliLTQ3NmEtODVjMy0wZjkxZTBiMzFiMzEifQ==\",\n",
        "    log_model_checkpoints=True,\n",
        "    name=name_experiment,\n",
        ")\n",
        "\n",
        "\n",
        "class BertConfig(Bert.modeling.BertConfig):\n",
        "    def __init__(self, config):\n",
        "        super(BertConfig, self).__init__(\n",
        "            vocab_size_or_config_json_file=config.get(\"vocab_size\"),\n",
        "            hidden_size=config[\"hidden_size\"],\n",
        "            num_hidden_layers=config.get(\"num_hidden_layers\"),\n",
        "            num_attention_heads=config.get(\"num_attention_heads\"),\n",
        "            intermediate_size=config.get(\"intermediate_size\"),\n",
        "            hidden_act=config.get(\"hidden_act\"),\n",
        "            hidden_dropout_prob=config.get(\"hidden_dropout_prob\"),\n",
        "            attention_probs_dropout_prob=config.get(\"attention_probs_dropout_prob\"),\n",
        "            max_position_embeddings=config.get(\"max_position_embedding\"),\n",
        "            initializer_range=config.get(\"initializer_range\"),\n",
        "        )\n",
        "        self.seg_vocab_size = config.get(\"seg_vocab_size\")\n",
        "        self.age_vocab_size = config.get(\"age_vocab_size\")\n",
        "        self.date_vocab_size = config.get(\"date_vocab_size\")\n",
        "        self.optim_param = config.get(\"optim_param\")\n",
        "\n",
        "\n",
        "if Azure:\n",
        "    os.environ['NEPTUNE_MODE'] = 'offline'\n",
        "    file_config = {\n",
        "        \"data_train\": \"../../EHR_data/data/pre_train_training_set.json\",  # formated data\n",
        "        \"data_val\": \"../../EHR_data/data/pre_train_validation_set.json\",  # formated data\n",
        "        \"model_path\": \"MLM/\" + name_experiment,  # where to save model\n",
        "        \"model_name\": \"behrt\",  # model name\n",
        "        \"vocab\": \"vocab.txt\",  # vocabulary idx2token, token2idx\n",
        "        \"file_name\": \"log.txt\",  # log path\n",
        "    }\n",
        "else:\n",
        "    file_config = {\n",
        "        \"data_train\": \"/Users/mikkelsinkjaer/data/data.json\",\n",
        "        \"data_val\": \"/Users/mikkelsinkjaer/data/data.json\",\n",
        "        \"model_path\": \"MLM/\" + name_experiment,  # where to save model\n",
        "        \"model_name\": \"behrt\",  # model name\n",
        "        \"vocab\": \"vocab.txt\",  # vocabulary idx2token, token2idx\n",
        "        \"file_name\": \"log.txt\",  # log path\n",
        "    }\n",
        "\n",
        "create_folder(file_config[\"model_path\"])\n",
        "\n",
        "global_params = {\"max_seq_len\": 512, \"gradient_accumulation_steps\": 1}\n",
        "\n",
        "optim_param = {\"lr\": 2e-5, \"warmup_proportion\": 0.1, \"weight_decay\": 0.01}\n",
        "\n",
        "train_params = {\n",
        "    \"batch_size\": 128,\n",
        "    \"max_len_seq\": global_params[\"max_seq_len\"],\n",
        "}\n",
        "\n",
        "# load data\n",
        "with open(file_config[\"data_train\"]) as f:\n",
        "    data_train_json = json.load(f)\n",
        "with open(file_config[\"data_val\"]) as f:\n",
        "    data_val_json = json.load(f)\n",
        "\n",
        "# Build vocab\n",
        "vocab_path = os.path.join(file_config[\"model_path\"], file_config[\"vocab\"])\n",
        "vocab_list, word_to_idx = build_vocab(\n",
        "    data_train_json,\n",
        "    save_file=vocab_path,\n",
        ")\n",
        "\n",
        "# Data loader\n",
        "masked_data_train = MaskedDataset(data_train_json, vocab_list, word_to_idx)\n",
        "trainload = DataLoader(\n",
        "    dataset=masked_data_train,\n",
        "    batch_size=train_params[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "    num_workers=6,\n",
        ")\n",
        "masked_data_val = MaskedDataset(data_val_json, vocab_list, word_to_idx)\n",
        "valload = DataLoader(\n",
        "    dataset=masked_data_val,\n",
        "    batch_size=train_params[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        "    num_workers=6,\n",
        ")\n",
        "\n",
        "# Model config\n",
        "model_config = {\n",
        "    \"vocab_size\": len(vocab_list),  # number of disease + symbols for word embedding\n",
        "    \"hidden_size\": 288,  # word embedding and seg embedding hidden size\n",
        "    \"seg_vocab_size\": 2,  # number of vocab for seg embedding\n",
        "    \"date_vocab_size\": int(\n",
        "        365.25 * 23\n",
        "    ),  # number of vocab for dates embedding --> days in 23 years\n",
        "    \"age_vocab_size\": 144,  # number of vocab for age embedding\n",
        "    \"max_position_embedding\": train_params[\"max_len_seq\"],  # maximum number of tokens\n",
        "    \"hidden_dropout_prob\": 0.1,  # dropout rate\n",
        "    \"num_hidden_layers\": 6,  # number of multi-head attention layers required\n",
        "    \"num_attention_heads\": 12,  # number of attention heads\n",
        "    \"attention_probs_dropout_prob\": 0.1,  # multi-head attention dropout rate\n",
        "    \"intermediate_size\": 512,  # the size of the \"intermediate\" layer in the transformer encoder\n",
        "    \"hidden_act\": \"gelu\",  # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
        "    \"initializer_range\": 0.02,  # parameter weight initializer range\n",
        "    \"optim_param\": optim_param,  # learning rate\n",
        "}\n",
        "\n",
        "# Checkopoint\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor=\"metrics/epoch/loss_val\",\n",
        "    dirpath=file_config[\"model_path\"] + \"/checkpoints\",\n",
        "    filename=\"checkpoint-{epoch:02d}\",\n",
        ")\n",
        "\n",
        "# Define model\n",
        "neptune_logger.log_hyperparams(model_config)\n",
        "model = BertModel(BertConfig(model_config))\n",
        "task = BertMLM(model, BertConfig(model_config))\n",
        "\n",
        "# Initialize the Trainer with the callback and Neptune logger\n",
        "trainer = pl.Trainer(\n",
        "    accelerator = 'gpu',\n",
        "    logger=neptune_logger,\n",
        "    max_epochs=10,\n",
        "    log_every_n_steps=100,\n",
        "    callbacks=checkpoint_callback,\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model as usual\n",
        "trainer.fit(model=task, train_dataloaders=trainload, val_dataloaders=valload)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchtext'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# sys.path.insert(0, \"../\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_folder\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataLoader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild_vocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_vocab\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_pretrained_bert\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mBert\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataLoader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataLoaderMLM\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaskedDataset\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/mikkel4c14/code/Users/mikkel.sinkjaer/transformerEHR/dataLoader/build_vocab.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Script to build vocabulary from a dataset and save it.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vocab\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691833283282
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
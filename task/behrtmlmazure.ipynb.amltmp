{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, Environment\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.script_run_config import ScriptRunConfig\n",
        "\n",
        "# Retrieve Workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Get the Curated Environment\n",
        "env = Environment.get(workspace=ws, name=\"AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\")\n",
        "\n",
        "# Create a Run Configuration\n",
        "run_config = RunConfiguration()\n",
        "run_config.environment = env\n",
        "\n",
        "# Define the Training Script and Directory\n",
        "script_folder = ''\n",
        "script_name = 'executeBehrtMLM.py'\n",
        "\n",
        "# Create an Experiment\n",
        "experiment_name = 'My-Experiment'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "\n",
        "# Configure and Submit the Training Job\n",
        "src = ScriptRunConfig(source_directory=script_folder,\n",
        "                      script=script_name,\n",
        "                      run_config=run_config)\n",
        "\n",
        "run = experiment.submit(src)\n",
        "run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: My-Experiment_1691763176_81b64fd8\nWeb View: https://ml.azure.com/runs/My-Experiment_1691763176_81b64fd8?wsid=/subscriptions/f8c5aac3-29fc-4387-858a-1f61722fb57a/resourcegroups/forskerpl-p2ss0q-rg/workspaces/forskerpl-p2ss0q-mlw&tid=421c9c18-32c7-4250-84e0-c1626f963b1f\n\nStreaming azureml-logs/60_control_log.txt\n=========================================\n\n[2023-08-11T14:13:01.248508] Using urllib.request Python 3.0 or later\nStreaming log file azureml-logs/60_control_log.txt\nRunning: ['/bin/bash', '/tmp/azureml_runs/My-Experiment_1691763176_81b64fd8/azureml-environment-setup/conda_env_checker.sh']Starting the daemon thread to refresh tokens in background for process with pid = 6215\n\n\n\nRunning: ['python', 'azureml-setup/run_script.py', 'python', 'azureml-setup/context_manager_injector.py', '-i', 'ProjectPythonPath:context_managers.ProjectPythonPath', '-i', 'RunHistory:context_managers.RunHistory', '-i', 'TrackUserError:context_managers.TrackUserError', 'executeBehrtMLM.py']\n[2023-08-11T14:13:01.755128] Logging experiment running status in history service.\nStreaming log file azureml-logs/70_driver_log.txt\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n\n[2023-08-11T14:13:01.984288] Entering context manager injector.\n[2023-08-11T14:13:02.806981] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['executeBehrtMLM.py'])\nScript type = None\n[2023-08-11T14:13:02.810181] Entering Run History Context Manager.\n[2023-08-11T14:13:05.350571] Current directory: /tmp/azureml_runs/My-Experiment_1691763176_81b64fd8\n[2023-08-11T14:13:05.350656] Preparing to call script [executeBehrtMLM.py] with arguments:[]\n[2023-08-11T14:13:05.350842] After variable expansion, calling script [executeBehrtMLM.py] with arguments:[]\n\n\n\n[2023-08-11T14:13:05.380226] The experiment failed. Finalizing run...\n[2023-08-11T14:13:05.380246] Start FinalizingInRunHistory\n[2023-08-11T14:13:05.381674] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 6235\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n3 items cleaning up...\nCleanup took 0.2673506736755371 seconds\nTraceback (most recent call last):\n  File \"executeBehrtMLM.py\", line 9, in <module>\n    from common.common import create_folder\nModuleNotFoundError: No module named 'common'\n\n[2023-08-11T14:13:06.602773] Finished context manager injector with Exception.\n\nExecution Summary\n=================\nRunId: My-Experiment_1691763176_81b64fd8\nWeb View: https://ml.azure.com/runs/My-Experiment_1691763176_81b64fd8?wsid=/subscriptions/f8c5aac3-29fc-4387-858a-1f61722fb57a/resourcegroups/forskerpl-p2ss0q-rg/workspaces/forskerpl-p2ss0q-mlw&tid=421c9c18-32c7-4250-84e0-c1626f963b1f\n\nWarnings:\nLocal execution of User Script failed. Details can be found in azureml-logs/60_control_log.txt log file.\n\n"
        },
        {
          "output_type": "error",
          "ename": "ActivityFailedException",
          "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with ModuleNotFoundError: No module named 'common'\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with ModuleNotFoundError: No module named 'common'\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m src \u001b[38;5;241m=\u001b[39m ScriptRunConfig(source_directory\u001b[38;5;241m=\u001b[39mscript_folder,\n\u001b[1;32m     25\u001b[0m                       script\u001b[38;5;241m=\u001b[39mscript_name,\n\u001b[1;32m     26\u001b[0m                       run_config\u001b[38;5;241m=\u001b[39mrun_config)\n\u001b[1;32m     28\u001b[0m run \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39msubmit(src)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azureml/core/run.py:849\u001b[0m, in \u001b[0;36mRun.wait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_output:\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_run_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile_handle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwait_post_processing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_post_processing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_details()\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azureml/core/run.py:1102\u001b[0m, in \u001b[0;36mRun._stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ActivityFailedException(error_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m   1104\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1105\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n",
            "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with ModuleNotFoundError: No module named 'common'\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with ModuleNotFoundError: No module named 'common'\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691763191266
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "# Get curated environment by name\n",
        "env = Environment.get(workspace=ws, name=\"behrt_gpu\")\n",
        "env"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "{\n    \"assetId\": \"azureml://locations/westeurope/workspaces/cd7411a6-1444-4dc7-ad9f-0eed2fcbd115/environments/behrt_gpu/versions/2\",\n    \"databricks\": {\n        \"eggLibraries\": [],\n        \"jarLibraries\": [],\n        \"mavenLibraries\": [],\n        \"pypiLibraries\": [],\n        \"rcranLibraries\": []\n    },\n    \"docker\": {\n        \"arguments\": [],\n        \"baseDockerfile\": null,\n        \"baseImage\": null,\n        \"baseImageRegistry\": null,\n        \"buildContext\": {\n            \"dockerfilePath\": \"Dockerfile\",\n            \"location\": \"https://forskerplp2ss0qstg.blob.core.windows.net/azureml/WebUpload/08-11-2023_105116_UTC-40b9a203-39c6-487c-8f25-cb286ac0a28b/\",\n            \"locationType\": \"storageAccount\"\n        },\n        \"enabled\": false,\n        \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"Linux\"\n        },\n        \"sharedVolumes\": true,\n        \"shmSize\": null\n    },\n    \"environmentVariables\": {},\n    \"inferencingStackVersion\": null,\n    \"name\": \"behrt_gpu\",\n    \"python\": {\n        \"baseCondaEnvironment\": null,\n        \"condaDependenciesFile\": null,\n        \"interpreterPath\": null,\n        \"userManagedDependencies\": true\n    },\n    \"r\": null,\n    \"spark\": {\n        \"packages\": [],\n        \"precachePackages\": true,\n        \"repositories\": []\n    },\n    \"version\": \"2\"\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691762741825
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "conda = CondaDependencies()\n",
        "\n",
        "# add channels\n",
        "conda.add_channel('pytorch')\n",
        "\n",
        "# add conda packages\n",
        "conda.add_conda_package('python=3.8')\n",
        "conda.add_conda_package('pytorch')\n",
        "conda.add_conda_package('torchvision')\n",
        "\n",
        "# add pip packages\n",
        "conda.add_pip_package('pyyaml')\n",
        "conda.add_pip_package('mpi4py')\n",
        "conda.add_pip_package('deepspeed')\n",
        "\n",
        "# create environment\n",
        "env = Environment('pytorch')\n",
        "env.python.conda_dependencies = conda"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1691751117331
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "env = Environment('pytorch-cuda')\n",
        "conda_dep = CondaDependencies()\n",
        "\n",
        "# Define the packages needed by the model and scripts\n",
        "conda_dep.add_conda_package('python=3.8')\n",
        "conda_dep.add_pip_package('pyyaml')\n",
        "conda_dep.add_pip_package('mpi4py')\n",
        "conda_dep.add_pip_package('deepspeed')\n",
        "\n",
        "# Add the dependencies to the environment\n",
        "env.python.conda_dependencies = conda_dep\n",
        "\n",
        "# Specify a Docker image that includes CUDA and PyTorch\n",
        "env.docker.enabled = True\n",
        "env.docker.base_image = \"AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\"\n",
        "\n",
        "# Create environment\n",
        "env.register(workspace=ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "from azureml.core import Environment\n",
        "\n",
        "env = Environment(\"behrt_gpu\")\n",
        "env.docker.base_image =\"behrt_gpu\"\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691751203005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from azureml.core import Environment\n",
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "curated_env_name = 'AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu'\n",
        "pytorch_env = Environment.get(workspace=ws, name=curated_env_name)\n",
        "print(pytorch_env.docker.base_image)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "None\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691751532129
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "env = Environment(name='my-env')\n",
        "\n",
        "env.docker.enabled = True\n",
        "env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691751310362
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, \"../\")\n",
        "from common.common import create_folder\n",
        "from dataLoader.build_vocab import build_vocab\n",
        "import pytorch_pretrained_bert as Bert\n",
        "from dataLoader.dataLoaderMLM import MaskedDataset\n",
        "from model.behrt import BertModel, BertMLM\n",
        "from torch.utils.data import DataLoader\n",
        "import json\n",
        "import os\n",
        "import lightning.pytorch as pl\n",
        "from lightning.pytorch.loggers import NeptuneLogger\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from lightning.pytorch.tuner import Tuner\n",
        "\n",
        "Azure = True\n",
        "\n",
        "# Initialize Neptune\n",
        "name_experiment = \"MLM_model\"\n",
        "neptune_logger = NeptuneLogger(\n",
        "    project=\"sinkjaer/BEHRT\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzOWVmOWI3Mi1jNjliLTQ3NmEtODVjMy0wZjkxZTBiMzFiMzEifQ==\",\n",
        "    log_model_checkpoints=True,\n",
        "    name=name_experiment,\n",
        ")\n",
        "\n",
        "\n",
        "class BertConfig(Bert.modeling.BertConfig):\n",
        "    def __init__(self, config):\n",
        "        super(BertConfig, self).__init__(\n",
        "            vocab_size_or_config_json_file=config.get(\"vocab_size\"),\n",
        "            hidden_size=config[\"hidden_size\"],\n",
        "            num_hidden_layers=config.get(\"num_hidden_layers\"),\n",
        "            num_attention_heads=config.get(\"num_attention_heads\"),\n",
        "            intermediate_size=config.get(\"intermediate_size\"),\n",
        "            hidden_act=config.get(\"hidden_act\"),\n",
        "            hidden_dropout_prob=config.get(\"hidden_dropout_prob\"),\n",
        "            attention_probs_dropout_prob=config.get(\"attention_probs_dropout_prob\"),\n",
        "            max_position_embeddings=config.get(\"max_position_embedding\"),\n",
        "            initializer_range=config.get(\"initializer_range\"),\n",
        "        )\n",
        "        self.seg_vocab_size = config.get(\"seg_vocab_size\")\n",
        "        self.age_vocab_size = config.get(\"age_vocab_size\")\n",
        "        self.date_vocab_size = config.get(\"date_vocab_size\")\n",
        "        self.optim_param = config.get(\"optim_param\")\n",
        "\n",
        "\n",
        "if Azure:\n",
        "    os.environ['NEPTUNE_MODE'] = 'offline'\n",
        "    file_config = {\n",
        "        \"data_train\": \"../../EHR_data/data/pre_train_training_set.json\",  # formated data\n",
        "        \"data_val\": \"../../EHR_data/data/pre_train_validation_set.json\",  # formated data\n",
        "        \"model_path\": \"MLM/\" + name_experiment,  # where to save model\n",
        "        \"model_name\": \"behrt\",  # model name\n",
        "        \"vocab\": \"vocab.txt\",  # vocabulary idx2token, token2idx\n",
        "        \"file_name\": \"log.txt\",  # log path\n",
        "    }\n",
        "else:\n",
        "    file_config = {\n",
        "        \"data_train\": \"/Users/mikkelsinkjaer/data/data.json\",\n",
        "        \"data_val\": \"/Users/mikkelsinkjaer/data/data.json\",\n",
        "        \"model_path\": \"MLM/\" + name_experiment,  # where to save model\n",
        "        \"model_name\": \"behrt\",  # model name\n",
        "        \"vocab\": \"vocab.txt\",  # vocabulary idx2token, token2idx\n",
        "        \"file_name\": \"log.txt\",  # log path\n",
        "    }\n",
        "\n",
        "create_folder(file_config[\"model_path\"])\n",
        "\n",
        "global_params = {\"max_seq_len\": 512, \"gradient_accumulation_steps\": 1}\n",
        "\n",
        "optim_param = {\"lr\": 2e-5, \"warmup_proportion\": 0.1, \"weight_decay\": 0.01}\n",
        "\n",
        "train_params = {\n",
        "    \"batch_size\": 128,\n",
        "    \"max_len_seq\": global_params[\"max_seq_len\"],\n",
        "}\n",
        "\n",
        "# load data\n",
        "with open(file_config[\"data_train\"]) as f:\n",
        "    data_train_json = json.load(f)\n",
        "with open(file_config[\"data_val\"]) as f:\n",
        "    data_val_json = json.load(f)\n",
        "\n",
        "# Build vocab\n",
        "vocab_path = os.path.join(file_config[\"model_path\"], file_config[\"vocab\"])\n",
        "vocab_list, word_to_idx = build_vocab(\n",
        "    data_train_json,\n",
        "    save_file=vocab_path,\n",
        ")\n",
        "\n",
        "# Data loader\n",
        "masked_data_train = MaskedDataset(data_train_json, vocab_list, word_to_idx)\n",
        "trainload = DataLoader(\n",
        "    dataset=masked_data_train,\n",
        "    batch_size=train_params[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "    num_workers=6,\n",
        ")\n",
        "masked_data_val = MaskedDataset(data_val_json, vocab_list, word_to_idx)\n",
        "valload = DataLoader(\n",
        "    dataset=masked_data_val,\n",
        "    batch_size=train_params[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        "    num_workers=6,\n",
        ")\n",
        "\n",
        "# Model config\n",
        "model_config = {\n",
        "    \"vocab_size\": len(vocab_list),  # number of disease + symbols for word embedding\n",
        "    \"hidden_size\": 288,  # word embedding and seg embedding hidden size\n",
        "    \"seg_vocab_size\": 2,  # number of vocab for seg embedding\n",
        "    \"date_vocab_size\": int(\n",
        "        365.25 * 23\n",
        "    ),  # number of vocab for dates embedding --> days in 23 years\n",
        "    \"age_vocab_size\": 144,  # number of vocab for age embedding\n",
        "    \"max_position_embedding\": train_params[\"max_len_seq\"],  # maximum number of tokens\n",
        "    \"hidden_dropout_prob\": 0.1,  # dropout rate\n",
        "    \"num_hidden_layers\": 6,  # number of multi-head attention layers required\n",
        "    \"num_attention_heads\": 12,  # number of attention heads\n",
        "    \"attention_probs_dropout_prob\": 0.1,  # multi-head attention dropout rate\n",
        "    \"intermediate_size\": 512,  # the size of the \"intermediate\" layer in the transformer encoder\n",
        "    \"hidden_act\": \"gelu\",  # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
        "    \"initializer_range\": 0.02,  # parameter weight initializer range\n",
        "    \"optim_param\": optim_param,  # learning rate\n",
        "}\n",
        "\n",
        "# Checkopoint\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor=\"metrics/epoch/loss_val\",\n",
        "    dirpath=file_config[\"model_path\"] + \"/checkpoints\",\n",
        "    filename=\"checkpoint-{epoch:02d}\",\n",
        ")\n",
        "\n",
        "# Define model\n",
        "neptune_logger.log_hyperparams(model_config)\n",
        "model = BertModel(BertConfig(model_config))\n",
        "task = BertMLM(model, BertConfig(model_config))\n",
        "\n",
        "# Initialize the Trainer with the callback and Neptune logger\n",
        "trainer = pl.Trainer(\n",
        "    accelerator = 'gpu',\n",
        "    logger=neptune_logger,\n",
        "    max_epochs=10,\n",
        "    log_every_n_steps=100,\n",
        "    callbacks=checkpoint_callback,\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model as usual\n",
        "trainer.fit(model=task, train_dataloaders=trainload, val_dataloaders=valload)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchtext'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_folder\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataLoader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild_vocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_vocab\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_pretrained_bert\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mBert\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataLoader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataLoaderMLM\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaskedDataset\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/mikkelgpu/code/Users/mikkel.sinkjaer/transformerEHR/dataLoader/build_vocab.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Script to build vocabulary from a dataset and save it.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vocab\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691762930308
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
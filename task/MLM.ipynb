{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.common import create_folder\n",
    "from common.pytorch import load_model\n",
    "from dataLoader.build_vocab import load_vocab\n",
    "import pytorch_pretrained_bert as Bert\n",
    "from common.common import load_obj\n",
    "from dataLoader.dataLoaderMLM import MaskedDataset, process_data_MLM\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from model.transModel import BertForMaskedLM\n",
    "from model.optimiser import adam\n",
    "import sklearn.metrics as skm\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get(\"vocab_size\"),\n",
    "            hidden_size=config[\"hidden_size\"],\n",
    "            num_hidden_layers=config.get(\"num_hidden_layers\"),\n",
    "            num_attention_heads=config.get(\"num_attention_heads\"),\n",
    "            intermediate_size=config.get(\"intermediate_size\"),\n",
    "            hidden_act=config.get(\"hidden_act\"),\n",
    "            hidden_dropout_prob=config.get(\"hidden_dropout_prob\"),\n",
    "            attention_probs_dropout_prob=config.get(\"attention_probs_dropout_prob\"),\n",
    "            max_position_embeddings=config.get(\"max_position_embedding\"),\n",
    "            initializer_range=config.get(\"initializer_range\"),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get(\"seg_vocab_size\")\n",
    "\n",
    "\n",
    "class TrainConfig(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get(\"batch_size\")\n",
    "        self.use_cuda = config.get(\"use_cuda\")\n",
    "        self.max_len_seq = config.get(\"max_len_seq\")\n",
    "        self.train_loader_workers = config.get(\"train_loader_workers\")\n",
    "        self.test_loader_workers = config.get(\"test_loader_workers\")\n",
    "        self.device = config.get(\"device\")\n",
    "        self.output_dir = config.get(\"output_dir\")\n",
    "        self.output_name = config.get(\"output_name\")\n",
    "        self.best_name = config.get(\"best_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config = {\n",
    "    \"vocab\": \"H:/Code/transformerEHR/data/vocab.txt\",  # vocabulary idx2token, token2idx\n",
    "    \"data\": \"H:/Code/transformerEHR/data/syntheticData.json\",  # formated data\n",
    "    \"model_path\": \"H:/Code/transformerEHR/model/weights\",  # where to save model\n",
    "    \"model_name\": \"test\",  # model name\n",
    "    \"file_name\": \"H:/Code/transformerEHR/model/log\",  # log path\n",
    "}\n",
    "create_folder(file_config[\"model_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\"max_seq_len\": 512, \"gradient_accumulation_steps\": 1}\n",
    "\n",
    "optim_param = {\"lr\": 3e-5, \"warmup_proportion\": 0.1, \"weight_decay\": 0.01}\n",
    "\n",
    "train_params = {\n",
    "    \"batch_size\": 256,\n",
    "    \"use_cuda\": True,\n",
    "    \"max_len_seq\": global_params[\"max_seq_len\"],\n",
    "    \"device\": \"cuda:0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list, word_to_idx = load_vocab(file_config[\"vocab\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_config[\"data\"]) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'birthdate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m process_data_MLM(data, vocab_list, word_to_idx)\n\u001b[0;32m      2\u001b[0m MaskedDataset \u001b[39m=\u001b[39m MaskedDataset(data)\n\u001b[0;32m      4\u001b[0m trainload \u001b[39m=\u001b[39m DataLoader(\n\u001b[0;32m      5\u001b[0m     dataset\u001b[39m=\u001b[39mMaskedDataset, batch_size\u001b[39m=\u001b[39mtrain_params[\u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m], shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mh:\\Code\\transformerEHR\\task\\..\\dataLoader\\dataLoaderMLM.py:56\u001b[0m, in \u001b[0;36mprocess_data_MLM\u001b[1;34m(data, vocab_list, word_to_idx, START_TOKEN, SEP_TOKEN, PAD_TOKEN, EMPTY_TOKEN_NS, ref_date, max_length)\u001b[0m\n\u001b[0;32m     53\u001b[0m processed_data \u001b[39m=\u001b[39m {}\n\u001b[0;32m     55\u001b[0m \u001b[39mfor\u001b[39;00m patient, patient_data \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> 56\u001b[0m     birth_date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mstrptime(patient_data[\u001b[39m\"\u001b[39;49m\u001b[39mbirthdate\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m     events \u001b[39m=\u001b[39m patient_data[\u001b[39m\"\u001b[39m\u001b[39mevents\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     58\u001b[0m     events\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m\"\u001b[39m\u001b[39madmdate\u001b[39m\u001b[39m\"\u001b[39m])  \u001b[39m# Sort events by 'admdate'\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'birthdate'"
     ]
    }
   ],
   "source": [
    "data = process_data_MLM(data, vocab_list, word_to_idx)\n",
    "MaskedDataset = MaskedDataset(data)\n",
    "\n",
    "trainload = DataLoader(\n",
    "    dataset=MaskedDataset, batch_size=train_params[\"batch_size\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\MSIN0034\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\MSIN0034\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\MSIN0034\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"h:\\Code\\transformerEHR\\task\\..\\dataLoader\\dataLoaderMLM.py\", line 27, in __getitem__\n    codes = torch.tensor(self.data[idx][\"codes_masked\"])\nKeyError: 'codes_masked'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(trainload))\n\u001b[0;32m      2\u001b[0m sample[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\MSIN0034\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\MSIN0034\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32mc:\\Users\\MSIN0034\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\MSIN0034\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\MSIN0034\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\MSIN0034\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\MSIN0034\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"h:\\Code\\transformerEHR\\task\\..\\dataLoader\\dataLoaderMLM.py\", line 27, in __getitem__\n    codes = torch.tensor(self.data[idx][\"codes_masked\"])\nKeyError: 'codes_masked'\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(trainload))\n",
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"vocab_size\": len(vocab_list),  # number of disease + symbols for word embedding\n",
    "    \"hidden_size\": 288,  # word embedding and seg embedding hidden size\n",
    "    \"seg_vocab_size\": 2,  # number of vocab for seg embedding\n",
    "    \"max_position_embedding\": train_params[\"max_len_seq\"],  # maximum number of tokens\n",
    "    \"hidden_dropout_prob\": 0.1,  # dropout rate\n",
    "    \"num_hidden_layers\": 6,  # number of multi-head attention layers required\n",
    "    \"num_attention_heads\": 12,  # number of attention heads\n",
    "    \"attention_probs_dropout_prob\": 0.1,  # multi-head attention dropout rate\n",
    "    \"intermediate_size\": 512,  # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    \"hidden_act\": \"gelu\",  # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    \"initializer_range\": 0.02,  # parameter weight initializer range\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertConfig' object has no attribute 'dates_vocab_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m conf \u001b[39m=\u001b[39m BertConfig(model_config)\n\u001b[1;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m BertForMaskedLM(conf)\n",
      "File \u001b[1;32mh:\\Code\\transformerEHR\\task\\..\\model\\transModel.py:151\u001b[0m, in \u001b[0;36mBertForMaskedLM.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config):\n\u001b[0;32m    150\u001b[0m     \u001b[39msuper\u001b[39m(BertForMaskedLM, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(config)\n\u001b[1;32m--> 151\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert \u001b[39m=\u001b[39m BertModel(config)\n\u001b[0;32m    152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls \u001b[39m=\u001b[39m Bert\u001b[39m.\u001b[39mmodeling\u001b[39m.\u001b[39mBertOnlyMLMHead(\n\u001b[0;32m    153\u001b[0m         config, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert\u001b[39m.\u001b[39membeddings\u001b[39m.\u001b[39mword_embeddings\u001b[39m.\u001b[39mweight\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_bert_weights)\n",
      "File \u001b[1;32mh:\\Code\\transformerEHR\\task\\..\\model\\transModel.py:90\u001b[0m, in \u001b[0;36mBertModel.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config):\n\u001b[0;32m     89\u001b[0m     \u001b[39msuper\u001b[39m(BertModel, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(config)\n\u001b[1;32m---> 90\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings \u001b[39m=\u001b[39m BertEmbeddings(config\u001b[39m=\u001b[39;49mconfig)\n\u001b[0;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m Bert\u001b[39m.\u001b[39mmodeling\u001b[39m.\u001b[39mBertEncoder(config\u001b[39m=\u001b[39mconfig)\n\u001b[0;32m     92\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39m=\u001b[39m Bert\u001b[39m.\u001b[39mmodeling\u001b[39m.\u001b[39mBertPooler(config)\n",
      "File \u001b[1;32mh:\\Code\\transformerEHR\\task\\..\\model\\transModel.py:20\u001b[0m, in \u001b[0;36mBertEmbeddings.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msegment_embeddings \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(\n\u001b[0;32m     14\u001b[0m     config\u001b[39m.\u001b[39mseg_vocab_size, config\u001b[39m.\u001b[39mhidden_size\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mage_embeddings \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(\n\u001b[0;32m     17\u001b[0m     config\u001b[39m.\u001b[39mmax_position_embeddings, config\u001b[39m.\u001b[39mhidden_size\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_position_embeddings \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(\n\u001b[1;32m---> 20\u001b[0m     config\u001b[39m.\u001b[39;49mdates_vocab_size, config\u001b[39m.\u001b[39mhidden_size\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposi_embeddings \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(\n\u001b[0;32m     23\u001b[0m     config\u001b[39m.\u001b[39mmax_position_embeddings, config\u001b[39m.\u001b[39mhidden_size\n\u001b[0;32m     24\u001b[0m )\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     )\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm \u001b[39m=\u001b[39m Bert\u001b[39m.\u001b[39mmodeling\u001b[39m.\u001b[39mBertLayerNorm(config\u001b[39m.\u001b[39mhidden_size, eps\u001b[39m=\u001b[39m\u001b[39m1e-12\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BertConfig' object has no attribute 'dates_vocab_size'"
     ]
    }
   ],
   "source": [
    "conf = BertConfig(model_config)\n",
    "model = BertForMaskedLM(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(train_params[\"device\"])\n",
    "optim = adam(params=list(model.named_parameters()), config=optim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(label, pred):\n",
    "    logs = nn.LogSoftmax()\n",
    "    label = label.cpu().numpy()\n",
    "    ind = np.where(label != -1)[0]\n",
    "    truepred = pred.detach().cpu().numpy()\n",
    "    truepred = truepred[ind]\n",
    "    truelabel = label[ind]\n",
    "    truepred = logs(torch.tensor(truepred))\n",
    "    outs = [np.argmax(pred_x) for pred_x in truepred.numpy()]\n",
    "    precision = skm.precision_score(truelabel, outs, average=\"micro\")\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e, loader):\n",
    "    tr_loss = 0\n",
    "    temp_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    cnt = 0\n",
    "    start = time.time()\n",
    "\n",
    "    for step, batch in enumerate(loader):\n",
    "        cnt += 1\n",
    "        batch = tuple(t.to(train_params[\"device\"]) for t in batch)\n",
    "        (\n",
    "            age_ids,\n",
    "            dates_ids,\n",
    "            input_ids,\n",
    "            posi_ids,\n",
    "            segment_ids,\n",
    "            attMask,\n",
    "            masked_label,\n",
    "        ) = batch\n",
    "        loss, pred, label = model(\n",
    "            input_ids,\n",
    "            dates_ids,\n",
    "            age_ids,\n",
    "            segment_ids,\n",
    "            posi_ids,\n",
    "            attention_mask=attMask,\n",
    "            masked_lm_labels=masked_label,\n",
    "        )\n",
    "        if global_params[\"gradient_accumulation_steps\"] > 1:\n",
    "            loss = loss / global_params[\"gradient_accumulation_steps\"]\n",
    "        loss.backward()\n",
    "\n",
    "        temp_loss += loss.item()\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"epoch: {}\\t| cnt: {}\\t|Loss: {}\\t| precision: {:.4f}\\t| time: {:.2f}\".format(\n",
    "                    e, cnt, temp_loss / 2000, cal_acc(label, pred), time.time() - start\n",
    "                )\n",
    "            )\n",
    "            temp_loss = 0\n",
    "            start = time.time()\n",
    "\n",
    "        if (step + 1) % global_params[\"gradient_accumulation_steps\"] == 0:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "    print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "    model_to_save = (\n",
    "        model.module if hasattr(model, \"module\") else model\n",
    "    )  # Only save the model it-self\n",
    "    create_folder(file_config[\"model_path\"])\n",
    "    output_model_file = os.path.join(\n",
    "        file_config[\"model_path\"], file_config[\"model_name\"]\n",
    "    )\n",
    "\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "\n",
    "    cost = time.time() - start\n",
    "    return tr_loss, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join(file_config[\"model_path\"], file_config[\"file_name\"]), \"w\")\n",
    "f.write(\"{}\\t{}\\t{}\\n\".format(\"epoch\", \"loss\", \"time\"))\n",
    "for e in range(50):\n",
    "    loss, time_cost = train(e, trainload)\n",
    "    loss = loss / 1  # data_len\n",
    "    f.write(\"{}\\t{}\\t{}\\n\".format(e, loss, time_cost))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
